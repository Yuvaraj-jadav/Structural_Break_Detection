{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-FCjE5rtSIw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('/content/drive/MyDrive/ML_projects/x-test.csv')\n",
        "x_train = pd.read_csv('/content/drive/MyDrive/ML_projects/x-train.csv')\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/ML_projects/y-test.csv')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/ML_projects/y-train.csv')"
      ],
      "metadata": {
        "id": "Ybe_tNiCtnNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.head()"
      ],
      "metadata": {
        "id": "TH72rxCbzoqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head()"
      ],
      "metadata": {
        "id": "G5KsEP5Kzs08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot time series for all unique IDs in x_train\n",
        "unique_ids_to_plot = x_train['id'].unique()\n",
        "\n",
        "for id in range(2):\n",
        "    sample_series = x_train[x_train['id'] == id].sort_values(by='time')\n",
        "\n",
        "    plt.figure(figsize=(200,5)) # Increased width\n",
        "    plt.plot(sample_series['time'], sample_series['value'])\n",
        "    plt.title(f'Time Series for ID: {id}')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Value')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hGTRUgrh5A6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.head()"
      ],
      "metadata": {
        "id": "rhveEQUxzwOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "BVMZVpboz0UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the x_train and y_train dataframes loaded previously\n",
        "# Assuming x_train has columns 'id', 'time', 'value' and y_train has 'id', 'structural_breakpoint'\n",
        "\n",
        "# Merge x_train and y_train to have labels associated with each time series\n",
        "# We need to ensure that the IDs in x_train and y_train match.\n",
        "# Let's assume y_train contains the ground truth for the IDs present in x_train.\n",
        "# We will process each unique time series (identified by 'id') in x_train.\n",
        "\n",
        "unique_ids = x_train['id'].unique()\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Determine a reasonable break point based on the structure of the time series data\n",
        "# If the time series length varies, this approach might need adjustment.\n",
        "# For now, let's assume a fixed break point or a method to estimate it per series.\n",
        "# Given the example data structure, let's assume a break point can be defined relative to the series length.\n",
        "# A simple approach is to take the midpoint, but a more robust method might be needed depending on the data.\n",
        "# For this example, let's assume a fixed break point of 100 or try to find a common length.\n",
        "# Let's first check the length of a few time series to get an idea.\n",
        "# Assuming time series are of similar length and break point is around the middle.\n",
        "# A more sophisticated approach would involve change point detection algorithms.\n",
        "\n",
        "# Let's use a simplified approach for demonstration, assuming break point is at half the length.\n",
        "# However, the original synthetic data used a fixed break_point=100. Let's try to stick to that if possible.\n",
        "# Let's check if the time series in x_train have at least 200 points as in the synthetic data.\n",
        "\n",
        "# Let's refine the feature extraction to handle time series of varying lengths if necessary,\n",
        "# or filter for time series of a specific length if a fixed break point is required.\n",
        "# For now, let's assume we can use a fixed break_point=100 as in the original code,\n",
        "# and filter out time series shorter than 200 if needed.\n",
        "\n",
        "def extract_features(series, break_point=100):\n",
        "    if len(series) < 2 * break_point:\n",
        "        # Handle short series, perhaps return NaNs or skip\n",
        "        return [np.nan] * 5\n",
        "\n",
        "    before = series[:break_point]\n",
        "    after = series[break_point:2*break_point] # Take equal length segments\n",
        "\n",
        "    # Handle cases where segments might be too short after splitting\n",
        "    if len(before) < break_point or len(after) < break_point:\n",
        "         return [np.nan] * 5\n",
        "\n",
        "    d_mean = np.mean(after) - np.mean(before)\n",
        "    d_var = np.var(after) - np.var(before)\n",
        "    d_std = np.std(after) - np.std(before)\n",
        "\n",
        "    # Handle cases with insufficient data points for skew/kurtosis\n",
        "    if len(before) < 2 or len(after) < 2: # Minimum 2 points for skew/kurtosis calculation\n",
        "         return [d_mean, d_var, d_std, np.nan, np.nan]\n",
        "\n",
        "    d_skew = skew(after) - skew(before)\n",
        "    d_kurt = kurtosis(after) - kurtosis(before)\n",
        "\n",
        "    return [d_mean, d_var, d_std, d_skew, d_kurt]\n",
        "\n",
        "features_list = []\n",
        "labels_list = []\n",
        "processed_ids = []\n",
        "\n",
        "for id in unique_ids:\n",
        "    time_series_data = x_train[x_train['id'] == id].sort_values(by='time')['value'].values\n",
        "    features = extract_features(time_series_data, break_point=100)\n",
        "\n",
        "    # Only add features and labels if features are not NaN (i.e., time series was long enough)\n",
        "    if not any(np.isnan(features)):\n",
        "        features_list.append(features)\n",
        "        # Find the corresponding label in y_train\n",
        "        label_row = y_train[y_train['id'] == id]\n",
        "        if not label_row.empty:\n",
        "            labels_list.append(label_row['structural_breakpoint'].iloc[0])\n",
        "            processed_ids.append(id)\n",
        "\n",
        "\n",
        "feature_matrix = np.array(features_list)\n",
        "labels = np.array(labels_list)\n",
        "\n",
        "# Create a DataFrame for clarity\n",
        "df = pd.DataFrame(feature_matrix, columns=['ΔMean', 'ΔVar', 'ΔStd', 'ΔSkew', 'ΔKurt'])\n",
        "df['Label'] = labels\n",
        "df['id'] = processed_ids\n",
        "\n",
        "\n",
        "print(\"Feature Sample:\")\n",
        "display(df.head())\n",
        "\n",
        "# -----------------------------------------------\n",
        "# STEP 3: Prepare Data for Training (using all extracted features from x_train/y_train)\n",
        "# -----------------------------------------------\n",
        "\n",
        "X_train = df[['ΔMean', 'ΔVar', 'ΔStd', 'ΔSkew', 'ΔKurt']]\n",
        "y_train_labels = df['Label']\n",
        "\n",
        "\n",
        "# -----------------------------------------------\n",
        "# STEP 4: Train Logistic Regression Model\n",
        "# Train the model on all extracted features from x_train and y_train\n",
        "# -----------------------------------------------\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train_labels)\n",
        "\n",
        "# -----------------------------------------------\n",
        "# STEP 5: Evaluation (Evaluation on separate x_test/y_test will be done in another cell)\n",
        "# You can still print a message indicating model training is complete.\n",
        "# -----------------------------------------------\n",
        "print(\"\\nLogistic Regression Model trained on x_train and y_train.\")"
      ],
      "metadata": {
        "id": "_r1Pw6oZBP7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHmr3ssVyDh-"
      },
      "source": [
        "# Use the x_test dataframe loaded previously\n",
        "# Assuming x_test has columns 'id', 'time', 'value'\n",
        "\n",
        "unique_test_ids = x_test['id'].unique()\n",
        "test_features_list = []\n",
        "test_processed_ids = []\n",
        "\n",
        "for id in unique_test_ids:\n",
        "    time_series_data = x_test[x_test['id'] == id].sort_values(by='time')['value'].values\n",
        "    features = extract_features(time_series_data, break_point=100)\n",
        "\n",
        "    # Only add features if features are not NaN (i.e., time series was long enough)\n",
        "    if not any(np.isnan(features)):\n",
        "        test_features_list.append(features)\n",
        "        test_processed_ids.append(id)\n",
        "\n",
        "test_feature_matrix = np.array(test_features_list)\n",
        "\n",
        "# Create a DataFrame for clarity\n",
        "df_test = pd.DataFrame(test_feature_matrix, columns=['ΔMean', 'ΔVar', 'ΔStd', 'ΔSkew', 'ΔKurt'])\n",
        "df_test['id'] = test_processed_ids\n",
        "\n",
        "print(\"Test Feature Sample:\")\n",
        "display(df_test.head())\n",
        "\n",
        "# Predict on the extracted test features using the trained model from the previous cell\n",
        "# Ensure the 'model' variable is available from a previous cell (e.g., _r1Pw6oZBP7w)\n",
        "X_test = df_test[['ΔMean', 'ΔVar', 'ΔStd', 'ΔSkew', 'ΔKurt']]\n",
        "y_pred_test = model.predict(X_test)\n",
        "y_prob_test = model.predict_proba(X_test)[:, 1] # Get probabilities for ROC AUC\n",
        "\n",
        "# Convert boolean predictions to 1/0\n",
        "y_pred_test_int = y_pred_test.astype(int)\n",
        "\n",
        "# Create a DataFrame with id and predictions\n",
        "predictions_df = pd.DataFrame({'id': test_processed_ids, 'predicted_structural_break': y_pred_test_int})\n",
        "\n",
        "# Create a DataFrame with id and probabilities (useful for ROC AUC calculation later)\n",
        "prob_df = pd.DataFrame({'id': test_processed_ids, 'predicted_prob_structural_break': y_prob_test})\n",
        "\n",
        "\n",
        "print(\"\\nTest Predictions (1/0 format):\")\n",
        "display(predictions_df.head())\n",
        "\n",
        "# Note: Evaluation against y_test is typically done in a separate cell\n",
        "# to clearly distinguish prediction from evaluation steps."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa598dd7"
      },
      "source": [
        "# Evaluate the model's predictions against the y_test dataset\n",
        "\n",
        "# Ensure predictions_df, prob_df, and y_test are available from previous cells\n",
        "# predictions_df contains the 1/0 predictions\n",
        "# prob_df contains the prediction probabilities\n",
        "# y_test contains the true labels\n",
        "\n",
        "# Merge predictions_df with y_test to evaluate against true labels\n",
        "merged_test_results = pd.merge(predictions_df, y_test, on='id', how='left')\n",
        "\n",
        "# Drop rows where y_test label is missing (for IDs in predictions_df but not in y_test)\n",
        "merged_test_results.dropna(subset=['structural_breakpoint'], inplace=True)\n",
        "\n",
        "# Ensure the true labels are boolean for evaluation metrics\n",
        "merged_test_results['structural_breakpoint'] = merged_test_results['structural_breakpoint'].astype(bool)\n",
        "\n",
        "\n",
        "print(\"\\nEvaluation on Test Data:\")\n",
        "print(classification_report(merged_test_results['structural_breakpoint'], merged_test_results['predicted_structural_break'], zero_division=0))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(merged_test_results['structural_breakpoint'], merged_test_results['predicted_structural_break']))\n",
        "print(\"Accuracy:\", accuracy_score(merged_test_results['structural_breakpoint'], merged_test_results['predicted_structural_break']))\n",
        "\n",
        "# Merge prob_df to include probabilities for ROC AUC calculation\n",
        "merged_test_results_with_prob = pd.merge(merged_test_results, prob_df, on='id', how='left')\n",
        "\n",
        "print(\"ROC AUC Score:\", roc_auc_score(merged_test_results_with_prob['structural_breakpoint'], merged_test_results_with_prob['predicted_prob_structural_break']))\n",
        "\n",
        "# Optional: Plot ROC Curve for test data\n",
        "fpr_test, tpr_test, thresholds_test = roc_curve(merged_test_results_with_prob['structural_breakpoint'], merged_test_results_with_prob['predicted_prob_structural_break'])\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_test, tpr_test, color='blue', label='ROC curve (AUC = %0.2f)' % roc_auc_score(merged_test_results_with_prob['structural_breakpoint'], merged_test_results_with_prob['predicted_prob_structural_break']))\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Structural Break Detection (Test Data)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}